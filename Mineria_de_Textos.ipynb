{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ferraresso/mineria_textos/blob/master/Mineria_de_Textos.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir input\n",
    "!wget -O input/train.csv.gz https://meli-data-challenge.s3.amazonaws.com/train.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm as tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduccion\n",
    "El trabajo realizado consiste en un modelo que pueda clasificar productos del sitio Mercado Libre, a partir del titulo que tiene el post de la venta. El dataset usado sale de una competencia (https://ml-challenge.mercadolibre.com) creada por la compañia, que probee 10 millones de ejemplos de productos, en idioma español y portugues.<br/>\n",
    "En este caso vamos a trabajar unicamente con el idioma español, aunque la misma metodologia funciona con similares resultados para el portuges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura y filtrado del dataset\n",
    "Primero, levantamos el dataset completo y filtramos para trabajar unicamente con el idioma español. Luego mostramos los primeros ejemplos del dataset filtrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de ejemplos 10000000\n"
     ]
    }
   ],
   "source": [
    "LANGUAGE = 'spanish'#'portuguese'\n",
    "train = pd.read_csv('input/train.csv.gz')\n",
    "train = train[train.language == LANGUAGE]\n",
    "print('Cantidad de ejemplos', train.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label_quality</th>\n",
       "      <th>language</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hidrolavadora Lavor One 120 Bar 1700w  Bomba A...</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>ELECTRIC_PRESSURE_WASHERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Placa De Sonido - Behringer Umc22</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>SOUND_CARDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Flashes Led Pestañas Luminoso Falso Pestañas P...</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>FALSE_EYELASHES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gatito Lunchera Neoprene</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>LUNCHBOXES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Rosario Contador De Billetes Uv / Mg Detecta F...</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>BILL_COUNTERS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title label_quality language  \\\n",
       "0   Hidrolavadora Lavor One 120 Bar 1700w  Bomba A...    unreliable  spanish   \n",
       "1                   Placa De Sonido - Behringer Umc22    unreliable  spanish   \n",
       "4   Flashes Led Pestañas Luminoso Falso Pestañas P...    unreliable  spanish   \n",
       "9                           Gatito Lunchera Neoprene     unreliable  spanish   \n",
       "11  Rosario Contador De Billetes Uv / Mg Detecta F...    unreliable  spanish   \n",
       "\n",
       "                     category  \n",
       "0   ELECTRIC_PRESSURE_WASHERS  \n",
       "1                 SOUND_CARDS  \n",
       "4             FALSE_EYELASHES  \n",
       "9                  LUNCHBOXES  \n",
       "11              BILL_COUNTERS  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede notar facilmente que los titulos son escritos de forma bastante concreta. Tambien se ve que suelen contener numeros y algunos caracteres raros. Las categorías estan nombradas en ingles, ahora veamos la cantidad de categorias que hay para los casos en español."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de categorias 1574\n"
     ]
    }
   ],
   "source": [
    "print('Cantidad de categorias', train.category.unique().shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrando ejemplos confiables\n",
    "El dataset contiene un atributo que indica la calidad de la categoria asignada. Las que tienen valor 'reliable' significa que la categoria fue chequeada por una persona, las que tienen 'unreliable' son categorias asignadas por el vendedor, pero que no fueron validadas por gente de Mercado Libre. A continuacion filtraremos para quedarnos las confiables, a ver cuanto representan del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de ejemplos confiables 490927\n"
     ]
    }
   ],
   "source": [
    "train = train[train.label_quality == 'reliable']\n",
    "print('Cantidad de ejemplos confiables', train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos queda un 5% del dataset total, lo que significa una reduccion muy importante. Ahora veamos si esos ejemplos cubren todas las categorias, y si quedan con una cantidad aceptable de casos para cada una."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de categorias 1062\n"
     ]
    }
   ],
   "source": [
    "print('Cantidad de categorias', train.category.unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x18ac938a0f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFcRJREFUeJzt3X+sXGd95/H3t85PxWycX1x5bWsdhFuR1lsTrkKqrFbXCUtCqOpUSioji3ghq9vdDRUIaxunldqyXaSwWpMubpf2FtM4rYuTBpCtEFplk4wQfyTBBhMnuGkuxEsu9trq2jFcoNl1+O4f85gZnLHveOaOr+8z75c0mnOeec6Z53wVf+bJuWfmRGYiSarXz831ACRJg2XQS1LlDHpJqpxBL0mVM+glqXIGvSRVzqCXpMoZ9JJUOYNekip33lwPAODKK6/M5cuX97TtD3/4Qy655JLZHdA8ZS2arEOLtWipsRa7d+/+x8y8aqZ+50TQL1++nF27dvW0baPRYGxsbHYHNE9Ziybr0GItWmqsRUT8r276eepGkipn0EtS5Qx6SaqcQS9JlTPoJalyBr0kVc6gl6TKGfSSVDmDXpIqN++Dfu/3jrF845dYvvFLcz0USTonzfuglySdnkEvSZUz6CWpcga9JFXOoJekyhn0klS5roM+IhZExDci4tGyfnVEPBMRL0XEQxFxQWm/sKxPlteXD2bokqRunMmM/sPAvrb1TwD3Z+YK4ChwV2m/CziamW8F7i/9JElzpKugj4ilwHuBz5T1AG4EHildtgK3leU1ZZ3y+k2lvyRpDnQ7o/8j4LeBn5T1K4BXM/N4WZ8ClpTlJcArAOX1Y6W/JGkOzHhz8Ij4VeBwZu6OiLETzR26Zhevte93HBgHGBkZodFodDPeNxi5GDasbH7e9LqPWkxPTw99DcA6tLMWLcNcixmDHrgB+LWIuBW4CPhnNGf4iyLivDJrXwocKP2ngGXAVEScB1wKHDl5p5k5AUwAjI6OZq93Z9+8bQeb9jYPY/+63vZRixrvct8L69BiLVqGuRYznrrJzHszc2lmLgfWAk9m5jrgKeD20m09sKMs7yzrlNefzMw3zOglSWdHP9fR3wN8NCImaZ6D31LatwBXlPaPAhv7G6IkqR/dnLr5qcxsAI2y/B3gug59/gm4YxbGJkmaBX4zVpIqZ9BLUuUMekmqnEEvSZUz6CWpcga9JFXOoJekyhn0klQ5g16SKmfQS1LlDHpJqpxBL0mVM+glqXIGvSRVzqCXpMoZ9JJUuRmDPiIuiohnI+KbEfFCRHystD8QES9HxJ7yWFXaIyI+FRGTEfFcRFw76IOQJJ1aN3eYeg24MTOnI+J84KsR8eXy2n/KzEdO6v8eYEV5vBP4dHmWJM2Bbm4Onpk5XVbPL4/T3ex7DfBg2e5pYFFELO5/qJKkXkTm6TK7dIpYAOwG3gr8SWbeExEPAL9Cc8b/BLAxM1+LiEeB+zLzq2XbJ4B7MnPXSfscB8YBRkZG3rF9+/aeDuDwkWMc+nFzeeWSS3vaRy2mp6dZuHDhXA9jzlmHFmvRUmMtVq9evTszR2fq19XNwTPzdWBVRCwCvhgRvwTcC/xv4AJgArgH+M9AdNpFh31OlO0YHR3NsbGxbobyBpu37WDT3uZh7F/X2z5q0Wg06LWONbEOLdaiZZhrcUZX3WTmq0ADuCUzD5bTM68BfwFcV7pNAcvaNlsKHJiFsUqSetDNVTdXlZk8EXEx8C7g70+cd4+IAG4Dni+b7ATuLFffXA8cy8yDAxm9JGlG3Zy6WQxsLefpfw54ODMfjYgnI+Iqmqdq9gD/vvR/DLgVmAR+BHxg9octSerWjEGfmc8Bb+/QfuMp+idwd/9DkyTNBr8ZK0mVM+glqXIGvSRVzqCXpMoZ9JJUOYNekipn0EtS5Qx6SaqcQS9JlTPoJalyBr0kVc6gl6TKGfSSVDmDXpIqZ9BLUuW6ucPURRHxbER8MyJeiIiPlfarI+KZiHgpIh6KiAtK+4VlfbK8vnywhyBJOp1uZvSvATdm5i8Dq4Bbyi0CPwHcn5krgKPAXaX/XcDRzHwrcH/pJ0maIzMGfbkB+HRZPb88ErgReKS0b6V531iANWWd8vpN5b6ykqQ50NU5+ohYEBF7gMPA48C3gVcz83jpMgUsKctLgFcAyuvHgCtmc9CSpO51c3NwMvN1YFVELAK+CLytU7fy3Gn2nic3RMQ4MA4wMjJCo9HoZihvMHIxbFjZ/LzpdR+1mJ6eHvoagHVoZy1ahrkWXQX9CZn5akQ0gOuBRRFxXpm1LwUOlG5TwDJgKiLOAy4FjnTY1wQwATA6OppjY2M9HcDmbTvYtLd5GPvX9baPWjQaDXqtY02sQ4u1aBnmWnRz1c1VZSZPRFwMvAvYBzwF3F66rQd2lOWdZZ3y+pOZ+YYZvSTp7OhmRr8Y2BoRC2h+MDycmY9GxLeA7RHxX4BvAFtK/y3AX0bEJM2Z/NoBjFuS1KUZgz4znwPe3qH9O8B1Hdr/CbhjVkYnSeqb34yVpMoZ9JJUOYNekipn0EtS5Qx6SaqcQS9JlTPoJalyBr0kVc6gl6TKGfSSVDmDXpIqZ9BLUuUMekmqnEEvSZUz6CWpcga9JFWum1sJLouIpyJiX0S8EBEfLu1/EBHfi4g95XFr2zb3RsRkRLwYETcP8gAkSafXza0EjwMbMvPrEfEmYHdEPF5euz8z/1t754i4hubtA38R+OfA/4yIn8/M12dz4JKk7sw4o8/Mg5n59bL8A5o3Bl9ymk3WANsz87XMfBmYpMMtByVJZ0dkZvedI5YDXwF+Cfgo8G+B7wO7aM76j0bEHwNPZ+ZflW22AF/OzEdO2tc4MA4wMjLyju3bt/d0AIePHOPQj5vLK5dc2tM+ajE9Pc3ChQvnehhzzjq0WIuWGmuxevXq3Zk5OlO/bk7dABARC4HPAx/JzO9HxKeBPwSyPG8CPghEh83f8GmSmRPABMDo6GiOjY11O5SfsXnbDjbtbR7G/nW97aMWjUaDXutYE+vQYi1ahrkWXV11ExHn0wz5bZn5BYDMPJSZr2fmT4A/p3V6ZgpY1rb5UuDA7A1ZknQmurnqJoAtwL7M/GRb++K2br8OPF+WdwJrI+LCiLgaWAE8O3tDliSdiW5O3dwAvB/YGxF7StvvAO+LiFU0T8vsB34TIDNfiIiHgW/RvGLnbq+4kaS5M2PQZ+ZX6Xze/bHTbPNx4ON9jEuSNEv8ZqwkVc6gl6TKGfSSVDmDXpIqZ9BLUuUMekmqnEEvSZUz6CWpcga9JFXOoJekyhn0klQ5g16SKmfQS1LlDHpJqpxBL0mV6+YOU8si4qmI2BcRL0TEh0v75RHxeES8VJ4vK+0REZ+KiMmIeC4irh30QUiSTq2bGf1xYENmvg24Hrg7Iq4BNgJPZOYK4ImyDvAemrcPXAGMA5+e9VFLkro2Y9Bn5sHM/HpZ/gGwD1gCrAG2lm5bgdvK8hrgwWx6Glh00v1lJUln0Rmdo4+I5cDbgWeAkcw8CM0PA+DNpdsS4JW2zaZKmyRpDnRzc3AAImIh8HngI5n5/YhOt5Ftdu3Qlh32N07z1A4jIyM0Go1uh/IzRi6GDSuPA/S8j1pMT08PfQ3AOrSzFi3DXIuugj4izqcZ8tsy8wul+VBELM7Mg+XUzOHSPgUsa9t8KXDg5H1m5gQwATA6OppjY2M9HcDmbTvYtLd5GPvX9baPWjQaDXqtY02sQ4u1aBnmWnRz1U0AW4B9mfnJtpd2AuvL8npgR1v7neXqm+uBYydO8UiSzr5uZvQ3AO8H9kbEntL2O8B9wMMRcRfwXeCO8tpjwK3AJPAj4AOzOmJJ0hmZMegz86t0Pu8OcFOH/gnc3ee4JEmzxG/GSlLlDHpJqpxBL0mVM+glqXIGvSRVzqCXpMoZ9JJUOYNekipn0EtS5Qx6SaqcQS9JlTPoJalyBr0kVc6gl6TKGfSSVDmDXpIq182tBD8bEYcj4vm2tj+IiO9FxJ7yuLXttXsjYjIiXoyImwc1cElSd7qZ0T8A3NKh/f7MXFUejwFExDXAWuAXyzb/IyIWzNZgJUlnbsagz8yvAEe63N8aYHtmvpaZL9O8b+x1fYxPktSnbm4Ofiofiog7gV3Ahsw8CiwBnm7rM1Xa3iAixoFxgJGRERqNRk+DGLkYNqw8DtDzPmoxPT099DUA69DOWrQMcy16DfpPA38IZHneBHyQzjcRz047yMwJYAJgdHQ0x8bGehrI5m072LS3eRj71/W2j1o0Gg16rWNNrEOLtWgZ5lr0dNVNZh7KzNcz8yfAn9M6PTMFLGvruhQ40N8QJUn96CnoI2Jx2+qvAyeuyNkJrI2ICyPiamAF8Gx/Q5Qk9WPGUzcR8TlgDLgyIqaA3wfGImIVzdMy+4HfBMjMFyLiYeBbwHHg7sx8fTBDlyR1Y8agz8z3dWjecpr+Hwc+3s+gJEmzx2/GSlLlDHpJqpxBL0mVM+glqXIGvSRVzqCXpMoZ9JJUOYNekipn0EtS5Qx6SaqcQS9JlTPoJalyBr0kVc6gl6TKGfSSVLkZgz4iPhsRhyPi+ba2yyPi8Yh4qTxfVtojIj4VEZMR8VxEXDvIwUuSZtbNzcEfAP4YeLCtbSPwRGbeFxEby/o9wHto3j5wBfBOmjcRf+dsDvh0lm/80s+s77/vvWfrrSXpnDXjjD4zvwIcOal5DbC1LG8FbmtrfzCbngYWnXR/WUnSWdbrOfqRzDwIUJ7fXNqXAK+09ZsqbZKkOdLNqZszER3asmPHiHFgHGBkZIRGo9HTG45cDBtWHu/4Wq/7nK+mp6eH7pg7sQ4t1qJlmGvRa9AfiojFmXmwnJo5XNqngGVt/ZYCBzrtIDMngAmA0dHRHBsb62kgm7ftYNPezoexf11v+5yvGo0GvdaxJtahxVq0DHMtej11sxNYX5bXAzva2u8sV99cDxw7cYpHkjQ3ZpzRR8TngDHgyoiYAn4fuA94OCLuAr4L3FG6PwbcCkwCPwI+MIAxS5LOwIxBn5nvO8VLN3Xom8Dd/Q5KkjR7/GasJFXOoJekyhn0klQ5g16SKmfQS1LlZvubseeU9h858wfOJA0rZ/SSVDmDXpIqZ9BLUuUMekmqnEEvSZUz6CWpcga9JFXOoJekyhn0klQ5g16SKtfXTyBExH7gB8DrwPHMHI2Iy4GHgOXAfuA3MvNof8OUJPVqNmb0qzNzVWaOlvWNwBOZuQJ4oqxLkubIIH7UbA3Ne8wCbAUawD0DeJ+e+WNnkoZJNG/z2uPGES8DR4EE/iwzJyLi1cxc1NbnaGZe1mHbcWAcYGRk5B3bt2/vaQyHjxzj0I972hSAlUsu7X3jc8z09DQLFy6c62HMOevQYi1aaqzF6tWrd7edTTmlfmf0N2TmgYh4M/B4RPx9txtm5gQwATA6OppjY2M9DWDzth1s2tv7Yexf19v7nosajQa91rEm1qHFWrQMcy36OkefmQfK82Hgi8B1wKGIWAxQng/3O0hJUu96DvqIuCQi3nRiGXg38DywE1hfuq0HdvQ7SElS7/o5dTMCfDEiTuznrzPzbyPia8DDEXEX8F3gjv6HKUnqVc9Bn5nfAX65Q/v/AW7qZ1CSpNnjN2MlqXIGvSRVzqCXpMoZ9JJUOYNekio3iN+6mVf83RtJtXNGL0mVG/oZfT/8vwFJ84EzekmqnDP6Ns7QJdXIGb0kVc4ZfRf6men7fwmS5pozekmqnDP6U2ifiZ9p+6lm7qfqc6p9+n8AkmaDQT8ETv4g8QNEGi4DC/qIuAX478AC4DOZed+g3ms+OtUsvpv+ZyOo/duCVI+BBH1ELAD+BPg3wBTwtYjYmZnfGsT7nWvONMT72U97nwduuWRW3vd079FP6M/XD4/5Ou5zgbU7NwxqRn8dMFnuQkVEbAfWAEMR9IN2ph8Ag9pvP39nGMYrmQZxzDO1b1h5nLEzHWgPY2o3V5OB+frfxdkQmTn7O424HbglM/9dWX8/8M7M/FCn/qOjo7lr166e3mvzth1s2uufGqD5j9pa9F6Hbj64+ul/pvuZjf1vWHmc31q3Ztb2P1vHPOh9dnJyLU6llw+wbrYZxAdjROzOzNEZ+w0o6O8Abj4p6K/LzN9q6zMOjJfVXwBe7PHtrgT+sY/h1sRaNFmHFmvRUmMt/kVmXjVTp0FN/6aAZW3rS4ED7R0ycwKY6PeNImJXN59ow8BaNFmHFmvRMsy1GNQXpr4GrIiIqyPiAmAtsHNA7yVJOo2BzOgz83hEfAj4O5qXV342M18YxHtJkk5vYH+5y8zHgMcGtf82fZ/+qYi1aLIOLdaiZWhrMZA/xkqSzh3+qJkkVW5eB31E3BIRL0bEZERsnOvxzLaI+GxEHI6I59vaLo+IxyPipfJ8WWmPiPhUqcVzEXFt2zbrS/+XImL9XBxLvyJiWUQ8FRH7IuKFiPhwaR+qekTERRHxbER8s9ThY6X96oh4phzTQ+UiCCLiwrI+WV5f3rave0v7ixFx89wcUX8iYkFEfCMiHi3rQ1mHGWXmvHzQ/CPvt4G3ABcA3wSumetxzfIx/mvgWuD5trb/CmwsyxuBT5TlW4EvAwFcDzxT2i8HvlOeLyvLl831sfVQi8XAtWX5TcA/ANcMWz3K8Swsy+cDz5TjexhYW9r/FPgPZfk/An9altcCD5Xla8q/mQuBq8u/pQVzfXw91OOjwF8Dj5b1oazDTI/5PKP/6c8sZOb/BU78zEI1MvMrwJGTmtcAW8vyVuC2tvYHs+lpYFFELAZuBh7PzCOZeRR4HLhl8KOfXZl5MDO/XpZ/AOwDljBk9SjHM11Wzy+PBG4EHintJ9fhRH0eAW6KiCjt2zPztcx8GZik+W9q3oiIpcB7gc+U9WAI69CN+Rz0S4BX2tanSlvtRjLzIDTDD3hzaT9VPaqrU/nf7rfTnM0OXT3K6Yo9wGGaH1TfBl7NzOOlS/sx/fR4y+vHgCuooA7AHwG/DfykrF/BcNZhRvM56KND2zBfQnSqelRVp4hYCHwe+Ehmfv90XTu0VVGPzHw9M1fR/Mb5dcDbOnUrz1XWISJ+FTicmbvbmzt0rboO3ZrPQT/jzyxU6lA5BUF5PlzaT1WPauoUEefTDPltmfmF0jy09cjMV4EGzXP0iyLixPdi2o/pp8dbXr+U5unA+V6HG4Bfi4j9NE/b3khzhj9sdejKfA76Yf2ZhZ3AiStF1gM72trvLFebXA8cK6cy/g54d0RcVq5IeXdpm1fK+dQtwL7M/GTbS0NVj4i4KiIWleWLgXfR/HvFU8DtpdvJdThRn9uBJ7P5V8idwNpyNcrVwArg2bNzFP3LzHszc2lmLqf5b//JzFzHkNWha3P91+B+HjSvrPgHmucof3euxzOA4/sccBD4fzRnHnfRPK/4BPBSeb689A2aN3v5NrAXGG3bzwdp/pFpEvjAXB9Xj7X4VzT/l/o5YE953Dps9QD+JfCNUofngd8r7W+hGVCTwN8AF5b2i8r6ZHn9LW37+t1SnxeB98z1sfVRkzFaV90MbR1O9/CbsZJUufl86kaS1AWDXpIqZ9BLUuUMekmqnEEvSZUz6CWpcga9JFXOoJekyv1/z8eGywz+bYIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.groupby('category')['title'].count().hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1062.000000\n",
       "mean      462.266478\n",
       "std       865.860784\n",
       "min         1.000000\n",
       "25%        19.000000\n",
       "50%        93.000000\n",
       "75%       453.500000\n",
       "max      4575.000000\n",
       "Name: title, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('category')['title'].count().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La primer observacion es que hay 512 categorias que no tienen ejemplos confiables. Lo segundo, es que hay un 25% de categorias que no llegan a 20 ejemplos, y la mitad no llega a tener 100 ejemplos. <br/>\n",
    "Estas dos observaciones nos marcan que es inevitable tener que incluir los datos que son menos confiables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregando datos no confiables\n",
    "Dado que hay categorias que tienen una buena cantidad de ejemplos confiables, la idea no es incluir los ejemplos menos confiables por partes iguales a cada categoría. Por ende, la incorporación de datos no confiables se va a hacer en 2 partes.\n",
    "- Primero, se van a incluir ejemplos de las categorias que no estan contempladas en los confiables. Se van a elegir mil ejemplos a azar de cada categoria.\n",
    "- Segundo, para cada categoria que no consiga llegar a los mil ejemplos confiables, se van a incluir ejemplos no confiables al azar para alcanzar esa cantidad. En los casos que no se llege a esa cantidad quedara el maximo disponible de esa categoria.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La cantidad de mil se elige para tratar de tener un dataset medianamente balaceado, queda pendiente hacer la prueba con otras cantidades para ver si generan mejoras en los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_un = pd.read_csv('input/train.csv.gz')\n",
    "train_un = train_un[train_un.language == LANGUAGE]\n",
    "train_un = train_un[train_un.label_quality == 'unreliable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de ejemplos menos confiables 9509073\n"
     ]
    }
   ],
   "source": [
    "print('Cantidad de ejemplos menos confiables', train_un.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtramos los ejemplos con categorias que no tenemos aun en train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9509073, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unkn_category = train_un[~train_un.category.isin(train['category'].unique())].category\n",
    "train_un.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validamos que sea la cantidad correcta de categorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unkn_category.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_SAMPLES_CATEGORY = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora debemos realizar el segundo punto. Para eso primero vemos cuantas categorias quedaron con menos de mil ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "916\n"
     ]
    }
   ],
   "source": [
    "g = train.groupby('category').count()\n",
    "g = g[g.title < MIN_SAMPLES_CATEGORY]\n",
    "unbancaled_cats = np.asarray(list(g.index))\n",
    "print(len(unbancaled_cats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unimos las dos lista de categorias que se deberian buscar entre las no confiables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1428,)\n"
     ]
    }
   ],
   "source": [
    "cats_to_add = np.concatenate([unkn_category.unique(), unbancaled_cats], axis=0)\n",
    "print(cats_to_add.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtramos el dataset de los menos confiables para que solo tenga categorias de esa lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7760739, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_add = train_un[train_un.category.isin(cats_to_add)]\n",
    "to_add.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos quedamos con a lo sumo 1000 ejemplos por cada categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1312936, 4)\n"
     ]
    }
   ],
   "source": [
    "g = to_add.groupby('category')\n",
    "g = pd.DataFrame(g.apply(lambda x: x.sample(min(len(x), MIN_SAMPLES_CATEGORY))).reset_index(drop=True))\n",
    "print(g.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los agregamos al train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1803863, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.concat([train, g], axis=0)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente comprobamos que train tenga todas las categorias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de categorias 1574\n"
     ]
    }
   ],
   "source": [
    "print('Cantidad de categorias', train.category.unique().shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claramente tenemos un aumento en la cantidad de ejemplos. Veamos como quedo la distribucion de ejemplos por categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x18b113859b0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.groupby('category')['title'].count().hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1574.000000\n",
       "mean     1146.037484\n",
       "std       577.676993\n",
       "min         2.000000\n",
       "25%      1000.000000\n",
       "50%      1016.000000\n",
       "75%      1173.750000\n",
       "max      4575.000000\n",
       "Name: title, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('category')['title'].count().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien quedaron algunas etiquetas con pocos ejemplos, mejoro mucho la cantidad en general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_un, to_add, g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpiando un poco los textos\n",
    "Se va a limpiar el texto de varias formas simples\n",
    "- Primero se convierte todo a minusculas y se eliminan los tildes, para evitar palabras duplicadas.\n",
    "- Luego se eliminarán algunos simbolos que no aportan a la descripcion de un producto.\n",
    "- Dado que los numeros se utilizan a veces como nombre de producto no se van a eliminar, pero si se van a reemplazar por un caracter comun (#) dado que generalmente la diferencia en el nro de un mismo texto indica diferentes versiones del mismo producto y no productos de tipos diferentes.\n",
    "- Por ultimo, se eliminan las stopwords comunes del español, salvo la palabra \"te\" que es un producto. Tambien se quitan los caracteres que queden sueltos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_clean_cnn(data):\n",
    "    new_str = data.lower()\n",
    "    new_str = new_str.replace(';', ' ')\n",
    "    new_str = new_str.replace('\"', ' ')\n",
    "    new_str = new_str.replace('!', ' ')\n",
    "    new_str = new_str.replace('?', ' ')\n",
    "    new_str = new_str.replace('.', ' ')\n",
    "    new_str = new_str.replace(',', ' ')\n",
    "    new_str = new_str.replace('(', ' ')\n",
    "    new_str = new_str.replace(')', ' ')\n",
    "    new_str = new_str.replace('=', ' ')\n",
    "    new_str = new_str.replace('#', ' ')\n",
    "    new_str = new_str.replace('$', ' ')\n",
    "    new_str = new_str.replace('/', ' ')\n",
    "    new_str = new_str.replace(']', ' ')\n",
    "    new_str = new_str.replace('[', ' ')\n",
    "    new_str = new_str.replace('-', ' ')\n",
    "    new_str = new_str.replace('-', ' ')\n",
    "    new_str = new_str.replace('º', ' ')\n",
    "    new_str = new_str.replace('á', 'a')\n",
    "    new_str = new_str.replace('é', 'e')\n",
    "    new_str = new_str.replace('í', 'i')\n",
    "    new_str = new_str.replace('ó', 'o')\n",
    "    new_str = new_str.replace('ú', 'u')\n",
    "\n",
    "    new_str = new_str.replace('0', '#')\n",
    "    new_str = new_str.replace('1', '#')\n",
    "    new_str = new_str.replace('2', '#')\n",
    "    new_str = new_str.replace('3', '#')\n",
    "    new_str = new_str.replace('4', '#')\n",
    "    new_str = new_str.replace('5', '#')\n",
    "    new_str = new_str.replace('6', '#')\n",
    "    new_str = new_str.replace('7', '#')\n",
    "    new_str = new_str.replace('8', '#')\n",
    "    new_str = new_str.replace('9', '#')\n",
    "\n",
    "    return new_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "reg_tokenizer = RegexpTokenizer(r'[A-Za-z]\\w+')\n",
    "stopword_set = set(stopwords.words(LANGUAGE))\n",
    "stopword_set.remove('te')\n",
    "def nlp_clean(data):\n",
    "    max_words = 0\n",
    "    new_data = []\n",
    "    for i,d in tqdm(enumerate(data)):\n",
    "        try:\n",
    "            new_str = d\n",
    "            new_str = nlp_clean_cnn(new_str)\n",
    "            dlist = reg_tokenizer.tokenize(new_str)\n",
    "            dlist = [d for d in dlist if d not in stopword_set]\n",
    "            dlist = [d for d in dlist if len(d) > 1]\n",
    "            new_data.append(' '.join(dlist))\n",
    "        except AttributeError:\n",
    "            new_data.append('sintexto')\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_words(corpus, n=None):\n",
    "    \"\"\"\n",
    "    List the top n words in a vocabulary according to occurrence in a text corpus.\n",
    "    \"\"\"\n",
    "    vec = CountVectorizer().fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in     vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "terminos = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1803863it [00:21, 85393.11it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label_quality</th>\n",
       "      <th>language</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>play station volante hooligans</td>\n",
       "      <td>reliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>GAME_CONSOLES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>pilas energizer max aa tira pilas</td>\n",
       "      <td>reliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>CELL_BATTERIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>afeitadora electrica philips hq envio gratis</td>\n",
       "      <td>reliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>SHAVING_MACHINES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>estufa calefactor volcan kcal salida mandy</td>\n",
       "      <td>reliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>HOME_HEATERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>reloj pared vox tronic blanco numeros cm garan...</td>\n",
       "      <td>reliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>WALL_CLOCKS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title label_quality language  \\\n",
       "267                     play station volante hooligans      reliable  spanish   \n",
       "272                  pilas energizer max aa tira pilas      reliable  spanish   \n",
       "287       afeitadora electrica philips hq envio gratis      reliable  spanish   \n",
       "386         estufa calefactor volcan kcal salida mandy      reliable  spanish   \n",
       "449  reloj pared vox tronic blanco numeros cm garan...      reliable  spanish   \n",
       "\n",
       "             category  \n",
       "267     GAME_CONSOLES  \n",
       "272    CELL_BATTERIES  \n",
       "287  SHAVING_MACHINES  \n",
       "386      HOME_HEATERS  \n",
       "449       WALL_CLOCKS  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terminos['title'] = nlp_clean(terminos['title'])\n",
    "terminos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscamos stopwords propias del contexto del problema\n",
    "Veamos el top 200 de palabras mas usadas luego de la limpieza, para ver de limpiar algunas mas que suelen ser muy usadas pero que en si no aportan a la descripcion del producto, serían stopwords propias del contexto de éste trabajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mm', 58995),\n",
       " ('cm', 58629),\n",
       " ('original', 50548),\n",
       " ('kit', 43165),\n",
       " ('led', 33145),\n",
       " ('kg', 30796),\n",
       " ('caja', 25921),\n",
       " ('madera', 25381),\n",
       " ('envio', 24556),\n",
       " ('gb', 24427),\n",
       " ('juego', 23638),\n",
       " ('unidades', 23020),\n",
       " ('negro', 22987),\n",
       " ('acero', 22849),\n",
       " ('set', 22781),\n",
       " ('oferta', 22362),\n",
       " ('usb', 20816),\n",
       " ('nuevo', 20346),\n",
       " ('pack', 19724),\n",
       " ('ml', 19709),\n",
       " ('mini', 19558),\n",
       " ('luz', 19435),\n",
       " ('ford', 19367),\n",
       " ('mesa', 19318),\n",
       " ('bateria', 19149),\n",
       " ('digital', 18703),\n",
       " ('doble', 17373),\n",
       " ('fiat', 17156),\n",
       " ('pro', 16789),\n",
       " ('blanco', 16609),\n",
       " ('aire', 16465),\n",
       " ('gratis', 16186),\n",
       " ('combo', 16093),\n",
       " ('color', 15966),\n",
       " ('renault', 15492),\n",
       " ('hp', 15489),\n",
       " ('mts', 15483),\n",
       " ('peugeot', 15264),\n",
       " ('bomba', 15249),\n",
       " ('funda', 15246),\n",
       " ('tapa', 14982),\n",
       " ('aluminio', 14711),\n",
       " ('cable', 14350),\n",
       " ('electrico', 14317),\n",
       " ('profesional', 14231),\n",
       " ('agua', 14077),\n",
       " ('soporte', 14000),\n",
       " ('vw', 13933),\n",
       " ('cuero', 13924),\n",
       " ('motor', 13793),\n",
       " ('camara', 13603),\n",
       " ('cocina', 13582),\n",
       " ('chevrolet', 13497),\n",
       " ('vidrio', 13472),\n",
       " ('reloj', 13021),\n",
       " ('control', 12849),\n",
       " ('electrica', 12751),\n",
       " ('uso', 12637),\n",
       " ('mujer', 12615),\n",
       " ('talle', 12600),\n",
       " ('tv', 12594),\n",
       " ('nueva', 12470),\n",
       " ('bebe', 12317),\n",
       " ('samsung', 12292),\n",
       " ('lts', 12214),\n",
       " ('hombre', 12185),\n",
       " ('portatil', 12088),\n",
       " ('baño', 11913),\n",
       " ('modelo', 11897),\n",
       " ('cuotas', 11704),\n",
       " ('tipo', 11353),\n",
       " ('porta', 11257),\n",
       " ('maquina', 11253),\n",
       " ('pc', 11213),\n",
       " ('bolsa', 11197),\n",
       " ('super', 11076),\n",
       " ('base', 10981),\n",
       " ('auto', 10912),\n",
       " ('azul', 10731),\n",
       " ('hd', 10729),\n",
       " ('aceite', 10618),\n",
       " ('marca', 10587),\n",
       " ('excelente', 10494),\n",
       " ('pulgadas', 10488),\n",
       " ('cc', 10320),\n",
       " ('sensor', 10320),\n",
       " ('freno', 10301),\n",
       " ('grande', 10106),\n",
       " ('filtro', 10015),\n",
       " ('black', 9912),\n",
       " ('placa', 9912),\n",
       " ('honda', 9909),\n",
       " ('calidad', 9905),\n",
       " ('embrague', 9825),\n",
       " ('cargador', 9546),\n",
       " ('completo', 9444),\n",
       " ('colores', 9427),\n",
       " ('guitarra', 9402),\n",
       " ('lampara', 9353),\n",
       " ('plegable', 9295),\n",
       " ('sony', 9106),\n",
       " ('litros', 9033),\n",
       " ('seguridad', 8897),\n",
       " ('envios', 8869),\n",
       " ('dvd', 8850),\n",
       " ('inoxidable', 8824),\n",
       " ('metal', 8754),\n",
       " ('impecable', 8751),\n",
       " ('plastico', 8732),\n",
       " ('niños', 8679),\n",
       " ('notebook', 8646),\n",
       " ('piezas', 8635),\n",
       " ('moto', 8617),\n",
       " ('espejo', 8605),\n",
       " ('silla', 8578),\n",
       " ('teclado', 8516),\n",
       " ('gr', 8438),\n",
       " ('premium', 8427),\n",
       " ('philips', 8299),\n",
       " ('pared', 8289),\n",
       " ('regalo', 8210),\n",
       " ('mano', 8202),\n",
       " ('vendo', 8140),\n",
       " ('ruedas', 8114),\n",
       " ('pelota', 7879),\n",
       " ('puerta', 7788),\n",
       " ('pileta', 7683),\n",
       " ('volkswagen', 7615),\n",
       " ('bajo', 7581),\n",
       " ('universal', 7559),\n",
       " ('pie', 7529),\n",
       " ('rojo', 7518),\n",
       " ('linea', 7484),\n",
       " ('accesorios', 7450),\n",
       " ('barra', 7449),\n",
       " ('plus', 7416),\n",
       " ('lote', 7340),\n",
       " ('bolso', 7302),\n",
       " ('vintage', 7301),\n",
       " ('plata', 7287),\n",
       " ('remoto', 7278),\n",
       " ('delantero', 7231),\n",
       " ('gol', 7187),\n",
       " ('bluetooth', 7166),\n",
       " ('disco', 7160),\n",
       " ('natural', 7160),\n",
       " ('cinta', 7152),\n",
       " ('alta', 7133),\n",
       " ('mas', 7121),\n",
       " ('lcd', 7090),\n",
       " ('verde', 7045),\n",
       " ('alto', 7041),\n",
       " ('exterior', 7039),\n",
       " ('yamaha', 7024),\n",
       " ('negra', 7022),\n",
       " ('cama', 6994),\n",
       " ('wifi', 6984),\n",
       " ('sillon', 6955),\n",
       " ('antiguo', 6948),\n",
       " ('hierro', 6939),\n",
       " ('panel', 6926),\n",
       " ('mochila', 6891),\n",
       " ('red', 6890),\n",
       " ('bicicleta', 6886),\n",
       " ('infantil', 6849),\n",
       " ('smart', 6839),\n",
       " ('diseño', 6790),\n",
       " ('gas', 6744),\n",
       " ('campera', 6659),\n",
       " ('guantes', 6642),\n",
       " ('mascara', 6611),\n",
       " ('casco', 6604),\n",
       " ('inalambrico', 6598),\n",
       " ('algodon', 6578),\n",
       " ('pantalla', 6564),\n",
       " ('estuche', 6558),\n",
       " ('gris', 6542),\n",
       " ('equipo', 6522),\n",
       " ('silicona', 6511),\n",
       " ('in', 6467),\n",
       " ('liquido', 6453),\n",
       " ('ps', 6406),\n",
       " ('inflable', 6368),\n",
       " ('gel', 6309),\n",
       " ('largo', 6295),\n",
       " ('usado', 6272),\n",
       " ('blanca', 6192),\n",
       " ('colchon', 6169),\n",
       " ('usa', 6164),\n",
       " ('llave', 6135),\n",
       " ('valvula', 6124),\n",
       " ('goma', 6093),\n",
       " ('mt', 6061),\n",
       " ('oficial', 6041),\n",
       " ('papel', 6000),\n",
       " ('rueda', 5961),\n",
       " ('pedal', 5961),\n",
       " ('citroen', 5949),\n",
       " ('golf', 5935),\n",
       " ('impresora', 5929)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_n_words(terminos.title, n=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ven varias palabras relacionadas con unidades de medida, que indican diferentes tamaños mas que productos diferentes, por lo que optaré por quitarlas. Tambien hay otras relacionada a la venta (como \"envio\", \"nueva\", \"oferta\", \"excelente\", etc) que no aportan a clasificar el producto, por lo que tambien opto por quitarlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(sentence):\n",
    "    stop = ['cm',\n",
    "            'original',\n",
    "            'mm',\n",
    "            'kit',\n",
    "            'kg',\n",
    "            'envio',\n",
    "            'gb',\n",
    "            'ml',\n",
    "            'unidades',\n",
    "            'set',\n",
    "            'negro',\n",
    "            'oferta',\n",
    "            'ford',\n",
    "            'pack',\n",
    "            'nuevo',\n",
    "            'gratis',\n",
    "            'combo',\n",
    "            'mts',\n",
    "            'lts',\n",
    "            'talle',\n",
    "            'nueva',\n",
    "            'nuevo',\n",
    "            'uso',\n",
    "            'cuotas',\n",
    "            'cc',\n",
    "            'tipo',\n",
    "            'excelente',\n",
    "            'pulgadas',\n",
    "            'litros',\n",
    "            'colores',\n",
    "            'color',\n",
    "            'calidad',\n",
    "            'gr',\n",
    "            'envios',\n",
    "            'impecable',\n",
    "            'completo',\n",
    "            'vendo',\n",
    "            'mas',\n",
    "]\n",
    "    return ' '.join([i for i in sentence.split() if i not in stop and len(i) > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label_quality</th>\n",
       "      <th>language</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>play station volante hooligans</td>\n",
       "      <td>reliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>GAME_CONSOLES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>pilas energizer max aa tira pilas</td>\n",
       "      <td>reliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>CELL_BATTERIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>afeitadora electrica philips hq</td>\n",
       "      <td>reliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>SHAVING_MACHINES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>estufa calefactor volcan kcal salida mandy</td>\n",
       "      <td>reliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>HOME_HEATERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>reloj pared vox tronic blanco numeros garantia...</td>\n",
       "      <td>reliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>WALL_CLOCKS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title label_quality language  \\\n",
       "267                     play station volante hooligans      reliable  spanish   \n",
       "272                  pilas energizer max aa tira pilas      reliable  spanish   \n",
       "287                    afeitadora electrica philips hq      reliable  spanish   \n",
       "386         estufa calefactor volcan kcal salida mandy      reliable  spanish   \n",
       "449  reloj pared vox tronic blanco numeros garantia...      reliable  spanish   \n",
       "\n",
       "             category  \n",
       "267     GAME_CONSOLES  \n",
       "272    CELL_BATTERIES  \n",
       "287  SHAVING_MACHINES  \n",
       "386      HOME_HEATERS  \n",
       "449       WALL_CLOCKS  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terminos['title'] = terminos['title'].apply(lambda x: remove_stopwords(nlp_clean_cnn(x)))\n",
    "terminos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('led', 33145),\n",
       " ('caja', 25921),\n",
       " ('madera', 25381),\n",
       " ('juego', 23638),\n",
       " ('acero', 22849),\n",
       " ('usb', 20816),\n",
       " ('mini', 19558),\n",
       " ('luz', 19435),\n",
       " ('mesa', 19318),\n",
       " ('bateria', 19149),\n",
       " ('digital', 18703),\n",
       " ('doble', 17373),\n",
       " ('fiat', 17156),\n",
       " ('pro', 16789),\n",
       " ('blanco', 16609),\n",
       " ('aire', 16465),\n",
       " ('renault', 15492),\n",
       " ('hp', 15489),\n",
       " ('peugeot', 15264),\n",
       " ('bomba', 15249),\n",
       " ('funda', 15246),\n",
       " ('tapa', 14982),\n",
       " ('aluminio', 14711),\n",
       " ('cable', 14350),\n",
       " ('electrico', 14317),\n",
       " ('profesional', 14231),\n",
       " ('agua', 14077),\n",
       " ('soporte', 14000),\n",
       " ('vw', 13933),\n",
       " ('cuero', 13924),\n",
       " ('motor', 13793),\n",
       " ('camara', 13603),\n",
       " ('cocina', 13582),\n",
       " ('chevrolet', 13497),\n",
       " ('vidrio', 13472),\n",
       " ('reloj', 13021),\n",
       " ('control', 12849),\n",
       " ('electrica', 12751),\n",
       " ('mujer', 12615),\n",
       " ('tv', 12594),\n",
       " ('bebe', 12317),\n",
       " ('samsung', 12292),\n",
       " ('hombre', 12185),\n",
       " ('portatil', 12088),\n",
       " ('baño', 11913),\n",
       " ('modelo', 11897),\n",
       " ('porta', 11257),\n",
       " ('maquina', 11253),\n",
       " ('pc', 11213),\n",
       " ('bolsa', 11197),\n",
       " ('super', 11076),\n",
       " ('base', 10981),\n",
       " ('auto', 10912),\n",
       " ('azul', 10731),\n",
       " ('hd', 10729),\n",
       " ('aceite', 10618),\n",
       " ('marca', 10587),\n",
       " ('sensor', 10320),\n",
       " ('freno', 10301),\n",
       " ('grande', 10106),\n",
       " ('filtro', 10015),\n",
       " ('black', 9912),\n",
       " ('placa', 9912),\n",
       " ('honda', 9909),\n",
       " ('embrague', 9825),\n",
       " ('cargador', 9546),\n",
       " ('guitarra', 9402),\n",
       " ('lampara', 9353),\n",
       " ('plegable', 9295),\n",
       " ('sony', 9106),\n",
       " ('seguridad', 8897),\n",
       " ('dvd', 8850),\n",
       " ('inoxidable', 8824),\n",
       " ('metal', 8754),\n",
       " ('plastico', 8732),\n",
       " ('niños', 8679),\n",
       " ('notebook', 8646),\n",
       " ('piezas', 8635),\n",
       " ('moto', 8617),\n",
       " ('espejo', 8605),\n",
       " ('silla', 8578),\n",
       " ('teclado', 8516),\n",
       " ('premium', 8427),\n",
       " ('philips', 8299),\n",
       " ('pared', 8289),\n",
       " ('regalo', 8210),\n",
       " ('mano', 8202),\n",
       " ('ruedas', 8114),\n",
       " ('pelota', 7879),\n",
       " ('puerta', 7788),\n",
       " ('pileta', 7683),\n",
       " ('volkswagen', 7615),\n",
       " ('bajo', 7581),\n",
       " ('universal', 7559),\n",
       " ('pie', 7529),\n",
       " ('rojo', 7518),\n",
       " ('linea', 7484),\n",
       " ('accesorios', 7450),\n",
       " ('barra', 7449),\n",
       " ('plus', 7416),\n",
       " ('lote', 7340),\n",
       " ('bolso', 7302),\n",
       " ('vintage', 7301),\n",
       " ('plata', 7287),\n",
       " ('remoto', 7278),\n",
       " ('delantero', 7231),\n",
       " ('gol', 7187),\n",
       " ('bluetooth', 7166),\n",
       " ('disco', 7160),\n",
       " ('natural', 7160),\n",
       " ('cinta', 7152),\n",
       " ('alta', 7133),\n",
       " ('lcd', 7090),\n",
       " ('verde', 7045),\n",
       " ('alto', 7041),\n",
       " ('exterior', 7039),\n",
       " ('yamaha', 7024),\n",
       " ('negra', 7022),\n",
       " ('cama', 6994),\n",
       " ('wifi', 6984),\n",
       " ('sillon', 6955),\n",
       " ('antiguo', 6948),\n",
       " ('hierro', 6939),\n",
       " ('panel', 6926),\n",
       " ('mochila', 6891),\n",
       " ('red', 6890),\n",
       " ('bicicleta', 6886),\n",
       " ('infantil', 6849),\n",
       " ('smart', 6839),\n",
       " ('diseño', 6790),\n",
       " ('gas', 6744),\n",
       " ('campera', 6659),\n",
       " ('guantes', 6642),\n",
       " ('mascara', 6611),\n",
       " ('casco', 6604),\n",
       " ('inalambrico', 6598),\n",
       " ('algodon', 6578),\n",
       " ('pantalla', 6564),\n",
       " ('estuche', 6558),\n",
       " ('gris', 6542),\n",
       " ('equipo', 6522),\n",
       " ('silicona', 6511),\n",
       " ('in', 6467),\n",
       " ('liquido', 6453),\n",
       " ('ps', 6406),\n",
       " ('inflable', 6368),\n",
       " ('gel', 6309),\n",
       " ('largo', 6295),\n",
       " ('usado', 6272),\n",
       " ('blanca', 6192),\n",
       " ('colchon', 6169),\n",
       " ('usa', 6164),\n",
       " ('llave', 6135),\n",
       " ('valvula', 6124),\n",
       " ('goma', 6093),\n",
       " ('mt', 6061),\n",
       " ('oficial', 6041),\n",
       " ('papel', 6000),\n",
       " ('rueda', 5961),\n",
       " ('pedal', 5961),\n",
       " ('citroen', 5949),\n",
       " ('golf', 5935),\n",
       " ('impresora', 5929),\n",
       " ('garantia', 5928),\n",
       " ('varios', 5925),\n",
       " ('manual', 5917),\n",
       " ('mp', 5917),\n",
       " ('importado', 5889),\n",
       " ('bosch', 5888),\n",
       " ('cepillo', 5876),\n",
       " ('coche', 5844),\n",
       " ('laser', 5781),\n",
       " ('micro', 5737),\n",
       " ('camiseta', 5693),\n",
       " ('futbol', 5666),\n",
       " ('ceramica', 5665),\n",
       " ('zona', 5657),\n",
       " ('conjunto', 5652),\n",
       " ('dos', 5645),\n",
       " ('trasero', 5645),\n",
       " ('full', 5624),\n",
       " ('chaleco', 5612),\n",
       " ('xl', 5609),\n",
       " ('asiento', 5571),\n",
       " ('video', 5569),\n",
       " ('rosa', 5505),\n",
       " ('toyota', 5485),\n",
       " ('par', 5472),\n",
       " ('memoria', 5459),\n",
       " ('audio', 5456),\n",
       " ('precio', 5432),\n",
       " ('radio', 5418),\n",
       " ('pedido', 5417),\n",
       " ('ideal', 5413),\n",
       " ('up', 5405),\n",
       " ('solo', 5385),\n",
       " ('direccion', 5364),\n",
       " ('banco', 5359),\n",
       " ('tubo', 5335),\n",
       " ('industrial', 5333)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_n_words(terminos.title, n=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Armar conjuntos de datos para train y test\n",
    "Primero vamos a mezclar los datos para que no alla nada del orden que pueda afectar y luego dividimos en dos partes para tener un conjunto de entrenamiento y otro de prueba. Dado que hay casi 2 millones de ejemplos, vamos a separar 90% para train y 10 para test, que nos deja con casi 200 mil ejemplos de prueba. Utilizamos la opcion \"stratify\" para que la distribucion de las etiquetas se mantenga entre test y train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label_quality</th>\n",
       "      <th>language</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23402</th>\n",
       "      <td>polea alternador zen reemplaza cargo</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>ALTERNATOR_PULLEYS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772677</th>\n",
       "      <td>tempera escolar maped peps metalica pote</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>MARKERS_AND_HIGHLIGHTERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096982</th>\n",
       "      <td>clips metal aluminio esteril vendas elasticos ...</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>SPORT_AND_MEDICAL_BANDAGES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57245</th>\n",
       "      <td>puerta trasera vw fox suran</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>AUTOMOTIVE_DOORS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603257</th>\n",
       "      <td>menzerna corta abrillanta encera detail center</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>HAND_POLISHERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646009</th>\n",
       "      <td>modulo encendido escort cabrio coupe</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>IGNITION_CONTROL_MODULES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573242</th>\n",
       "      <td>pinza pico loro blister</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>GROOVE_JOINT_PLIERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105403</th>\n",
       "      <td>espatula herramienta apertura yaxun yx spudger...</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>STEEL_SCRAPERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869168</th>\n",
       "      <td>switch rackeable tp link ports tl sg</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>NETWORK_SWITCHES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846790</th>\n",
       "      <td>the little horror shop tiendita horrores taza ...</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>MUGS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     title label_quality  \\\n",
       "23402                 polea alternador zen reemplaza cargo    unreliable   \n",
       "772677            tempera escolar maped peps metalica pote    unreliable   \n",
       "1096982  clips metal aluminio esteril vendas elasticos ...    unreliable   \n",
       "57245                          puerta trasera vw fox suran    unreliable   \n",
       "603257      menzerna corta abrillanta encera detail center    unreliable   \n",
       "646009                modulo encendido escort cabrio coupe    unreliable   \n",
       "573242                             pinza pico loro blister    unreliable   \n",
       "1105403  espatula herramienta apertura yaxun yx spudger...    unreliable   \n",
       "869168                switch rackeable tp link ports tl sg    unreliable   \n",
       "846790   the little horror shop tiendita horrores taza ...    unreliable   \n",
       "\n",
       "        language                    category  \n",
       "23402    spanish          ALTERNATOR_PULLEYS  \n",
       "772677   spanish    MARKERS_AND_HIGHLIGHTERS  \n",
       "1096982  spanish  SPORT_AND_MEDICAL_BANDAGES  \n",
       "57245    spanish            AUTOMOTIVE_DOORS  \n",
       "603257   spanish              HAND_POLISHERS  \n",
       "646009   spanish    IGNITION_CONTROL_MODULES  \n",
       "573242   spanish         GROOVE_JOINT_PLIERS  \n",
       "1105403  spanish              STEEL_SCRAPERS  \n",
       "869168   spanish            NETWORK_SWITCHES  \n",
       "846790   spanish                        MUGS  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terminos = terminos.sample(frac=1.0)\n",
    "terminos.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1623476, 4)\n",
      "(180387, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(terminos, test_size=0.1, stratify=terminos.category)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repredentacion de documentos\n",
    "Para este trabaja se va a usar CSA (Concise Semantic Analysis) para representar las palabras. Luego se van a representar los documentos como un arreglo de los vectores CSA de cada palabra existente en el documento. La implementacion de CSA fue hecha por mi usando como referencia las diapositivas del curso. Dado que partimos entre train/test, para hacer mas real el uso de test, los vectores de las palabras para CSA se realizan usando solo train, y luego se aplican tambien a los ejemplos de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero armamos el vocabulario de palabras y contamos la cantidad de apariciones. En este punto tambien se pueden incorparar ngramas de diferentes longitudes o hacerlo a niver de caracteres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=400000, min_df=0.0,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features = 400000\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=max_features,\n",
    "                             ngram_range=(1,1), min_df=0.0)\n",
    "vectorizer.fit(train['title'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207705"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = train['title'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora le asignamos un valor numerico a cada posible etiqueta, que luego se usara como indice de colimna en la matriz de coeficientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_ = LabelEncoder()\n",
    "le_.fit(train.category)\n",
    "labels = le_.transform(train.category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "del terminos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una matriz vacia de tamaño vocabulario x etiquetas. En esta matriz se iran guardando los coeficientes de frecuencia de cada palabra por cada etiqueta. Se crea como tamaño vocabulario+1 para utlizar la posicion cero como padding para textos de tamaño menor al definido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207705, 1574)\n"
     ]
    }
   ],
   "source": [
    "matrix = np.zeros((len(vectorizer.vocabulary_)+1, len(le_.classes_)))\n",
    "print(matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero cuenta y calcula los coeficientes por palabra de documento y luego lo normaliza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1623476it [00:38, 42157.24it/s]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import regexp_tokenize\n",
    "from nltk.util import ngrams\n",
    "for i,title in tqdm(enumerate(titles)):\n",
    "    tokens = regexp_tokenize(title, pattern='(?u)\\\\b\\\\w\\\\w+\\\\b')\n",
    "    for token in set(tokens):\n",
    "        cf_dh = np.log2(1+(tokens.count(token)/len(tokens)))\n",
    "        t_idx = vectorizer.vocabulary_[token]\n",
    "        l_idx = labels[i]\n",
    "        matrix[t_idx, l_idx] = matrix[t_idx, l_idx] + cf_dh\n",
    "norm_matrix = (matrix / matrix.sum(axis=0))\n",
    "norm_matrix = (matrix.T / matrix.sum(axis=1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207705, 1574)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del matrix\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora convertimos cada ejemplo de train a su correspondiente colleccion de arreglos, convirtiendo cada palabra a su indice en el vocabulario. Para eso primero determinamos cuantas palabras por titulo se van a incorporar al arreglo, dado que no todas los titulos tienen la misma longitud y algunos pueden ser demasiado largos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x18a07982ef0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['title'].apply(lambda x: len(x.split(' '))).hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ve que con una longitud de 10 se soporta la mayoria de los ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_samples(titles, maxlen=25):\n",
    "    samples = []\n",
    "    unkown_token =[]\n",
    "    unkown_title =[]\n",
    "    \n",
    "    for i,title in tqdm(enumerate(titles)):\n",
    "        tokens = regexp_tokenize(title, pattern='(?u)\\\\b\\\\w\\\\w+\\\\b')\n",
    "        x = []\n",
    "        for token in tokens[:maxlen]:\n",
    "            try:\n",
    "                t_idx = vectorizer.vocabulary_[token]\n",
    "                x.append(t_idx+1)\n",
    "            except KeyError:\n",
    "                unkown_token.append((token))\n",
    "        if len(x) == 0:\n",
    "            unkown_title.append(i)\n",
    "        for _ in range(len(x),maxlen):\n",
    "            x.append(0)\n",
    "        samples.append(x)\n",
    "    return np.asarray(samples), unkown_token,unkown_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1623476it [00:18, 86112.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1623476, 10) (1623476,)\n"
     ]
    }
   ],
   "source": [
    "x_train, _, _ = create_samples(train['title'].values,maxlen = maxlen)\n",
    "y_train = np.asarray(labels)\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label_quality</th>\n",
       "      <th>language</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65069</th>\n",
       "      <td>clutch thunderbird</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>AUTOMOTIVE_FRONT_BUMPERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004413</th>\n",
       "      <td>day fix extreme programa guias dvd digital</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>RESISTANCE_BANDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491231</th>\n",
       "      <td>suavizante triple fragancia limpieza</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>FABRIC_SOFTENERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316919</th>\n",
       "      <td>fusiogas codo ff saladillo termofusion gas</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>CONNECTING_COUPLERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841662</th>\n",
       "      <td>luz giro izquierda trasera zanella ceccato mt</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>MOTORCYCLE_TURN_SIGNAL_LIGHTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title label_quality language  \\\n",
       "65069                               clutch thunderbird    unreliable  spanish   \n",
       "1004413     day fix extreme programa guias dvd digital    unreliable  spanish   \n",
       "491231            suavizante triple fragancia limpieza    unreliable  spanish   \n",
       "316919      fusiogas codo ff saladillo termofusion gas    unreliable  spanish   \n",
       "841662   luz giro izquierda trasera zanella ceccato mt    unreliable  spanish   \n",
       "\n",
       "                              category  \n",
       "65069         AUTOMOTIVE_FRONT_BUMPERS  \n",
       "1004413               RESISTANCE_BANDS  \n",
       "491231                FABRIC_SOFTENERS  \n",
       "316919             CONNECTING_COUPLERS  \n",
       "841662   MOTORCYCLE_TURN_SIGNAL_LIGHTS  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180387it [00:02, 82795.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180387, 10) (180387,)\n",
      "Cantidad de palabras desconocidas en test 11309\n",
      "Cantidad de titulos de los que no se conocia ninguna palabra 119\n"
     ]
    }
   ],
   "source": [
    "x_val, unknown_token, unknown_title = create_samples(test['title'].values,maxlen = maxlen)\n",
    "y_val = np.asarray(le_.transform(test['category']))\n",
    "print(x_val.shape, y_val.shape)\n",
    "print('Cantidad de palabras desconocidas en test', len(unknown_token))\n",
    "print('Cantidad de titulos de los que no se conocia ninguna palabra', len(unknown_title))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos los titulos de los que no se conocieron palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label_quality</th>\n",
       "      <th>language</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142440</th>\n",
       "      <td>tdtt</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>BICYCLE_AND_MOTORCYCLE_ALARMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554617</th>\n",
       "      <td></td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>GAUZES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7820</th>\n",
       "      <td>parquerguitarra</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>ACOUSTIC_GUITARS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049376</th>\n",
       "      <td></td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>SECURITY_SEALS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142929</th>\n",
       "      <td></td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>BICYCLE_AND_MOTORCYCLE_ALARMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5889286</th>\n",
       "      <td>dermacool</td>\n",
       "      <td>reliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>FOUNDATIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271452</th>\n",
       "      <td></td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>CHIP_AND_DIP_SERVERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81849</th>\n",
       "      <td>gazeboz</td>\n",
       "      <td>reliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>GAZEBOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14809058</th>\n",
       "      <td>dïsa</td>\n",
       "      <td>reliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>NECKLACES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18893039</th>\n",
       "      <td>caniya larrouse</td>\n",
       "      <td>reliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>BATHROOM_FAUCETS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807119</th>\n",
       "      <td></td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>MONEY_BOXES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216698</th>\n",
       "      <td>viniloparafrascos</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>CARDS_AND_INVITATIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417632</th>\n",
       "      <td>martyncho</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>DRYWALLS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918739</th>\n",
       "      <td>dediles</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>PENIS_SLEEVES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788502</th>\n",
       "      <td></td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>MERCHANDISER_REFRIGERATORS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173441</th>\n",
       "      <td></td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>THERMOMETERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337090</th>\n",
       "      <td>peugeon peugeon peugeon</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>CRASHED_CARS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604500</th>\n",
       "      <td>parmil</td>\n",
       "      <td>reliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>LED_STAGE_LIGHTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512663</th>\n",
       "      <td>mush</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>FLATS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295500</th>\n",
       "      <td>cogniac</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>COGNACS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            title label_quality language  \\\n",
       "142440                       tdtt    unreliable  spanish   \n",
       "554617                               unreliable  spanish   \n",
       "7820              parquerguitarra    unreliable  spanish   \n",
       "1049376                              unreliable  spanish   \n",
       "142929                               unreliable  spanish   \n",
       "5889286                 dermacool      reliable  spanish   \n",
       "271452                               unreliable  spanish   \n",
       "81849                     gazeboz      reliable  spanish   \n",
       "14809058                     dïsa      reliable  spanish   \n",
       "18893039          caniya larrouse      reliable  spanish   \n",
       "807119                               unreliable  spanish   \n",
       "216698          viniloparafrascos    unreliable  spanish   \n",
       "417632                  martyncho    unreliable  spanish   \n",
       "918739                    dediles    unreliable  spanish   \n",
       "788502                               unreliable  spanish   \n",
       "1173441                              unreliable  spanish   \n",
       "337090    peugeon peugeon peugeon    unreliable  spanish   \n",
       "1604500                    parmil      reliable  spanish   \n",
       "512663                       mush    unreliable  spanish   \n",
       "295500                    cogniac    unreliable  spanish   \n",
       "\n",
       "                               category  \n",
       "142440    BICYCLE_AND_MOTORCYCLE_ALARMS  \n",
       "554617                           GAUZES  \n",
       "7820                   ACOUSTIC_GUITARS  \n",
       "1049376                  SECURITY_SEALS  \n",
       "142929    BICYCLE_AND_MOTORCYCLE_ALARMS  \n",
       "5889286                     FOUNDATIONS  \n",
       "271452             CHIP_AND_DIP_SERVERS  \n",
       "81849                           GAZEBOS  \n",
       "14809058                      NECKLACES  \n",
       "18893039               BATHROOM_FAUCETS  \n",
       "807119                      MONEY_BOXES  \n",
       "216698            CARDS_AND_INVITATIONS  \n",
       "417632                         DRYWALLS  \n",
       "918739                    PENIS_SLEEVES  \n",
       "788502       MERCHANDISER_REFRIGERATORS  \n",
       "1173441                    THERMOMETERS  \n",
       "337090                     CRASHED_CARS  \n",
       "1604500                LED_STAGE_LIGHTS  \n",
       "512663                            FLATS  \n",
       "295500                          COGNACS  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.iloc[unknown_title].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se notan varios con errores de tipeos, otros que quedaron vacios luego del prosesamiento, seguramente por tener un solo caracter o se solamente stopwords o simbolos raros. Dado que la cantidad es demasiado baja no se van a tomar acciones para corregirlos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenando el modelo de clasificacion\n",
    "Se van a intentar dos modelos tipos de modelos diferentes para clasificar los titulos. El primero de ellos basados en redes convolucionales y el segundo utilizando redes recurrentes LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que las etiquetas tienen diferente cantidad de ejemplos se van a usar pesos para balancear los ejemplos durante el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weights = dict(zip(np.unique(y_train), compute_class_weight('balanced', np.unique(y_train), y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo CNN\n",
    "A continuacion definimos un modelo utilizando bloques de Convoluciones de 1 dimension y Max Pooling. Segudo de dos capas completamente conectadas (Dense) y usando Dropout entre ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1216 18:56:59.561217  6956 deprecation_wrapper.py:119] From c:\\users\\aferraresso\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1216 18:56:59.967750  6956 deprecation_wrapper.py:119] From c:\\users\\aferraresso\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1216 18:57:00.161729  6956 deprecation_wrapper.py:119] From c:\\users\\aferraresso\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1216 18:57:00.619850  6956 deprecation_wrapper.py:119] From c:\\users\\aferraresso\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1216 18:57:00.782567  6956 deprecation_wrapper.py:119] From c:\\users\\aferraresso\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W1216 18:57:01.339110  6956 deprecation.py:506] From c:\\users\\aferraresso\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1216 18:57:01.507009  6956 deprecation_wrapper.py:119] From c:\\users\\aferraresso\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1216 18:57:01.526921  6956 deprecation_wrapper.py:119] From c:\\users\\aferraresso\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "import keras.layers as L\n",
    "\n",
    "filter_nr = 128\n",
    "filter_size = 3\n",
    "max_pool_size = 2\n",
    "max_pool_strides = 2\n",
    "# dense_nr = 512\n",
    "denses = [512,512]\n",
    "spatial_dropout = 0.0\n",
    "dense_dropout = 0.2\n",
    "\n",
    "\n",
    "title = L.Input(shape=(maxlen,))\n",
    "emb_comment = L.Embedding(norm_matrix.shape[0], norm_matrix.shape[1],  trainable=False, name='emb_words')(title)\n",
    "# emb_comment = L.SpatialDropout1D(spatial_dropout)(emb_comment)\n",
    "\n",
    "block1 = L.Conv1D(filter_nr, kernel_size=filter_size, padding='same', activation='linear')(emb_comment)\n",
    "block1 = L.BatchNormalization()(block1)\n",
    "block1 = L.Activation('relu')(block1)\n",
    "block1 = L.Conv1D(filter_nr, kernel_size=filter_size, padding='same', activation='linear')(block1)\n",
    "block1 = L.BatchNormalization()(block1)\n",
    "block1 = L.PReLU()(block1)\n",
    "\n",
    "activation_inner= 'relu'\n",
    "#we pass embedded comment through conv1d with filter size 1 because it needs to have the same shape as block output\n",
    "#if you choose filter_nr = embed_size (300 in this case) you don't have to do this part and can add emb_comment directly to block1_output\n",
    "resize_emb = L.Conv1D(filter_nr, kernel_size=1, padding='same', activation=activation_inner)(emb_comment)\n",
    "resize_emb = L.Activation('relu')(resize_emb)\n",
    "    \n",
    "block1_output = L.add([block1, resize_emb])\n",
    "block1_output = L.MaxPooling1D(pool_size=max_pool_size, strides=max_pool_strides)(block1_output)\n",
    "\n",
    "block2 = L.Conv1D(filter_nr, kernel_size=filter_size, padding='same', activation=activation_inner)(block1_output)\n",
    "block2 = L.BatchNormalization()(block2)\n",
    "block2 = L.Activation('relu')(block2)\n",
    "block2 = L.Conv1D(filter_nr, kernel_size=filter_size, padding='same', activation=activation_inner)(block2)\n",
    "block2 = L.BatchNormalization()(block2)\n",
    "block2 = L.Activation('relu')(block2)\n",
    "block2_output = L.add([block2, block1_output])\n",
    "block2_output = L.MaxPooling1D(pool_size=max_pool_size, strides=max_pool_strides)(block2_output)\n",
    "\n",
    "block3 = L.Conv1D(filter_nr, kernel_size=filter_size, padding='same', activation=activation_inner)(block2_output)\n",
    "block3 = L.BatchNormalization()(block3)\n",
    "block3 = L.Activation('relu')(block3)\n",
    "block3 = L.Conv1D(filter_nr, kernel_size=filter_size, padding='same', activation=activation_inner)(block3)\n",
    "block3 = L.BatchNormalization()(block3)\n",
    "block3 = L.Activation('relu')(block3)\n",
    "    \n",
    "block3_output = L.add([block3, block2_output])\n",
    "block3_output = L.MaxPooling1D(pool_size=max_pool_size, strides=max_pool_strides)(block3_output)\n",
    "\n",
    "output = L.Flatten()(block3_output)\n",
    "for dense_nr in denses:\n",
    "    output = L.Dense(dense_nr, activation=activation_inner)(output)\n",
    "    output = L.BatchNormalization()(output)\n",
    "    output = L.Activation('relu')(output)\n",
    "    output = L.Dropout(dense_dropout)(output)\n",
    "output = L.Dense(len(le_.classes_), activation='softmax')(output)\n",
    "\n",
    "model = Model(title, output)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "emb_words (Embedding)           (None, 10, 1574)     326927670   input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 10, 128)      604544      emb_words[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 10, 128)      512         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 10, 128)      0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 10, 128)      49280       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 10, 128)      512         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 10, 128)      201600      emb_words[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_1 (PReLU)               (None, 10, 128)      1280        batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 10, 128)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 10, 128)      0           p_re_lu_1[0][0]                  \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 5, 128)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 5, 128)       49280       max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 5, 128)       512         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 5, 128)       0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 5, 128)       49280       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 5, 128)       512         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 5, 128)       0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 5, 128)       0           activation_4[0][0]               \n",
      "                                                                 max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 2, 128)       0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 2, 128)       49280       max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 2, 128)       512         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 2, 128)       0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 2, 128)       49280       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 2, 128)       512         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 2, 128)       0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 2, 128)       0           activation_6[0][0]               \n",
      "                                                                 max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 1, 128)       0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 128)          0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          66048       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 512)          2048        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 512)          0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          262656      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 512)          2048        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 512)          0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512)          0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1574)         807462      dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 329,124,828\n",
      "Trainable params: 2,193,574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-trainable params: 326,931,254\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 196"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1216 18:57:02.673423  6956 deprecation.py:323] From c:\\users\\aferraresso\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1623476 samples, validate on 180387 samples\n",
      "Epoch 1/40\n",
      " - 342s - loss: 2.8079 - acc: 0.5477 - val_loss: 1.5181 - val_acc: 0.7182\n",
      "Epoch 2/40\n",
      " - 295s - loss: 1.5182 - acc: 0.7234 - val_loss: 1.2758 - val_acc: 0.7583\n",
      "Epoch 3/40\n",
      " - 289s - loss: 1.2621 - acc: 0.7614 - val_loss: 1.1430 - val_acc: 0.7800\n",
      "Epoch 4/40\n",
      " - 290s - loss: 1.1089 - acc: 0.7840 - val_loss: 1.0731 - val_acc: 0.7916\n",
      "Epoch 5/40\n",
      " - 288s - loss: 1.0093 - acc: 0.7977 - val_loss: 1.0058 - val_acc: 0.8016\n",
      "Epoch 6/40\n",
      " - 287s - loss: 0.9284 - acc: 0.8085 - val_loss: 0.9889 - val_acc: 0.8061\n",
      "Epoch 7/40\n",
      " - 287s - loss: 0.8705 - acc: 0.8169 - val_loss: 0.9558 - val_acc: 0.8124\n",
      "Epoch 8/40\n",
      " - 287s - loss: 0.8237 - acc: 0.8235 - val_loss: 0.9445 - val_acc: 0.8153\n",
      "Epoch 9/40\n",
      " - 290s - loss: 0.7851 - acc: 0.8289 - val_loss: 0.9417 - val_acc: 0.8152\n",
      "Epoch 10/40\n",
      " - 294s - loss: 0.7503 - acc: 0.8344 - val_loss: 0.9382 - val_acc: 0.8174\n",
      "Epoch 11/40\n",
      " - 298s - loss: 0.7217 - acc: 0.8385 - val_loss: 0.9296 - val_acc: 0.8178\n",
      "Epoch 12/40\n",
      " - 297s - loss: 0.6950 - acc: 0.8418 - val_loss: 0.9401 - val_acc: 0.8181\n",
      "Epoch 13/40\n",
      " - 293s - loss: 0.6666 - acc: 0.8456 - val_loss: 0.9387 - val_acc: 0.8204\n",
      "Epoch 14/40\n",
      " - 291s - loss: 0.6462 - acc: 0.8484 - val_loss: 0.9398 - val_acc: 0.8221\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 15/40\n",
      " - 292s - loss: 0.5424 - acc: 0.8684 - val_loss: 0.9255 - val_acc: 0.8290\n",
      "Epoch 16/40\n",
      " - 292s - loss: 0.5066 - acc: 0.8748 - val_loss: 0.9369 - val_acc: 0.8292\n",
      "Epoch 17/40\n",
      " - 292s - loss: 0.4886 - acc: 0.8782 - val_loss: 0.9475 - val_acc: 0.8289\n",
      "Epoch 18/40\n",
      " - 292s - loss: 0.4731 - acc: 0.8804 - val_loss: 0.9595 - val_acc: 0.8284\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 19/40\n",
      " - 293s - loss: 0.4419 - acc: 0.8858 - val_loss: 0.9694 - val_acc: 0.8292\n",
      "Epoch 20/40\n",
      " - 293s - loss: 0.4331 - acc: 0.8872 - val_loss: 0.9740 - val_acc: 0.8292\n",
      "Epoch 21/40\n",
      " - 292s - loss: 0.4296 - acc: 0.8877 - val_loss: 0.9790 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 22/40\n",
      " - 292s - loss: 0.4235 - acc: 0.8890 - val_loss: 0.9791 - val_acc: 0.8291\n",
      "Epoch 00022: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras import callbacks\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(factor=0.2, min_lr=1e-10, patience=3, monitor='val_loss', verbose=1)\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=7)\n",
    "history = model.fit(x_train, y_train,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[reduce_lr, es],\n",
    "                    class_weight=class_weights,\n",
    "                    verbose=2,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=40\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El entrenamiento nos da una accuracy de 81-82% (en diferentes ejecuciones) en el test que definimos. Veamos como le va con el Balanced Accuracy, una metrica que es util en casos de datasets desbalanceados. Se obtiene calculando el recall de cada clase y luego promediandolos todos. Esta fue la metrica que se definió en la competencia para definir los ganadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aferraresso\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8211227980890373\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(x_val)\n",
    "val_pred = preds.argmax(axis=-1)\n",
    "print(balanced_accuracy_score(y_val, val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos dio un score de 82.1 para el conjunto de Test que definimos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos ahora si el modelo predijo al menos un ejemplo para cada categoria que hubiera en test (que son todas al haber hecho el split usando \"stratified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1572, 1573)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(y_val)), len(np.unique(val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo recurrente\n",
    "A continuacion hacemos la prueba con un modelo de redes recurrentes. Esta compuesto por una capa LSTM seguido de dos capas densas como las usadas en CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "import keras.layers as L\n",
    "\n",
    "lstm_hiddens = 128\n",
    "denses = [512,512]\n",
    "spatial_dropout = 0.0\n",
    "dense_dropout = 0.2\n",
    "\n",
    "\n",
    "title = L.Input(shape=(maxlen,))\n",
    "emb_comment = L.Embedding(norm_matrix.shape[0], norm_matrix.shape[1],  trainable=False, name='emb_words')(title)\n",
    "\n",
    "output = L.LSTM(lstm_hiddens, return_sequences=False) (emb_comment)\n",
    "\n",
    "for dense_nr in denses:\n",
    "    output = L.Dense(dense_nr, activation=activation_inner)(output)\n",
    "    output = L.BatchNormalization()(output)\n",
    "    output = L.Activation('relu')(output)\n",
    "    output = L.Dropout(dense_dropout)(output)\n",
    "output = L.Dense(len(le_.classes_), activation='softmax')(output)\n",
    "\n",
    "model_lstm = Model(title, output)\n",
    "model_lstm.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "emb_words (Embedding)        (None, 10, 1574)          326927670 \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               871936    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1574)              807462    \n",
      "=================================================================\n",
      "Total params: 328,939,868\n",
      "Trainable params: 2,010,150\n",
      "Non-trainable params: 326,929,718\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponemos a entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1623476 samples, validate on 180387 samples\n",
      "Epoch 1/40\n",
      " - 439s - loss: 2.7073 - acc: 0.5612 - val_loss: 1.7800 - val_acc: 0.6782\n",
      "Epoch 2/40\n",
      " - 439s - loss: 1.5558 - acc: 0.7204 - val_loss: 1.4581 - val_acc: 0.7288\n",
      "Epoch 3/40\n",
      " - 437s - loss: 1.2966 - acc: 0.7586 - val_loss: 1.1313 - val_acc: 0.7828\n",
      "Epoch 4/40\n",
      " - 450s - loss: 1.1552 - acc: 0.7791 - val_loss: 1.0579 - val_acc: 0.7939\n",
      "Epoch 5/40\n",
      " - 455s - loss: 1.0637 - acc: 0.7921 - val_loss: 1.0017 - val_acc: 0.8054\n",
      "Epoch 6/40\n",
      " - 450s - loss: 0.9969 - acc: 0.8019 - val_loss: 0.9536 - val_acc: 0.8123\n",
      "Epoch 7/40\n",
      " - 460s - loss: 0.9432 - acc: 0.8100 - val_loss: 0.9191 - val_acc: 0.8192\n",
      "Epoch 8/40\n",
      " - 458s - loss: 0.9003 - acc: 0.8158 - val_loss: 0.9156 - val_acc: 0.8186\n",
      "Epoch 9/40\n",
      " - 456s - loss: 0.8653 - acc: 0.8211 - val_loss: 0.8917 - val_acc: 0.8240\n",
      "Epoch 10/40\n",
      " - 455s - loss: 0.8343 - acc: 0.8256 - val_loss: 0.8809 - val_acc: 0.8257\n",
      "Epoch 11/40\n",
      " - 455s - loss: 0.8042 - acc: 0.8299 - val_loss: 0.8830 - val_acc: 0.8254\n",
      "Epoch 12/40\n",
      " - 458s - loss: 0.7827 - acc: 0.8331 - val_loss: 0.8684 - val_acc: 0.8290\n",
      "Epoch 13/40\n",
      " - 448s - loss: 0.7616 - acc: 0.8362 - val_loss: 0.8648 - val_acc: 0.8291\n",
      "Epoch 14/40\n",
      " - 447s - loss: 0.7416 - acc: 0.8391 - val_loss: 0.8640 - val_acc: 0.8308\n",
      "Epoch 15/40\n",
      " - 447s - loss: 0.7244 - acc: 0.8416 - val_loss: 0.8628 - val_acc: 0.8307\n",
      "Epoch 16/40\n",
      " - 445s - loss: 0.7081 - acc: 0.8440 - val_loss: 0.8653 - val_acc: 0.8305\n",
      "Epoch 17/40\n",
      " - 441s - loss: 0.6943 - acc: 0.8459 - val_loss: 0.8628 - val_acc: 0.8310\n",
      "Epoch 18/40\n",
      " - 444s - loss: 0.6805 - acc: 0.8478 - val_loss: 0.8688 - val_acc: 0.8317\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 19/40\n",
      " - 445s - loss: 0.6059 - acc: 0.8620 - val_loss: 0.8540 - val_acc: 0.8377\n",
      "Epoch 20/40\n",
      " - 465s - loss: 0.5849 - acc: 0.8654 - val_loss: 0.8515 - val_acc: 0.8379\n",
      "Epoch 21/40\n",
      " - 446s - loss: 0.5726 - acc: 0.8673 - val_loss: 0.8553 - val_acc: 0.8382\n",
      "Epoch 22/40\n",
      " - 449s - loss: 0.5619 - acc: 0.8683 - val_loss: 0.8592 - val_acc: 0.8382\n",
      "Epoch 23/40\n",
      " - 452s - loss: 0.5552 - acc: 0.8692 - val_loss: 0.8603 - val_acc: 0.8379\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 24/40\n",
      " - 458s - loss: 0.5381 - acc: 0.8724 - val_loss: 0.8630 - val_acc: 0.8388\n",
      "Epoch 25/40\n",
      " - 447s - loss: 0.5353 - acc: 0.8730 - val_loss: 0.8643 - val_acc: 0.8388\n",
      "Epoch 26/40\n",
      " - 457s - loss: 0.5324 - acc: 0.8736 - val_loss: 0.8655 - val_acc: 0.8388\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 27/40\n",
      " - 439s - loss: 0.5277 - acc: 0.8742 - val_loss: 0.8651 - val_acc: 0.8388\n",
      "Epoch 00027: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras import callbacks\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(factor=0.2, min_lr=1e-10, patience=3, monitor='val_loss', verbose=1)\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=7)\n",
    "history = model_lstm.fit(x_train, y_train,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[reduce_lr, es],\n",
    "                    class_weight=class_weights,\n",
    "                    verbose=2,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=40\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo recurrente nos esta dando mejores resultados, ya sea mirando el resultado de la funcion de loss (que tiene una gran mejora) como en el accuracy general, que sube rondado el 1% respecto del modelo con CNN. Veamos si esa mejora se da tambien utilizando balanced accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.831938371216354\n"
     ]
    }
   ],
   "source": [
    "preds_lstm = model_lstm.predict(x_val)\n",
    "val_pred_lstm = preds_lstm.argmax(axis=-1)\n",
    "print(balanced_accuracy_score(y_val, val_pred_lstm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claramente se mantiene la mejora en los resultados obtenidos por el modelo recurrente, sobre el modelo con capas convolucionales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1572, 1573)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(y_val)), len(np.unique(val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que el modelo con CNN, el modelo recurrente produjo al menos un resultado de cada clase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Que pasa si mezclamos los resultados de los modelos\n",
    "Como se ve, los modelos tienen diferentes resultados, y al provenir de diferentes formas muy diferentes sobre como procesar los datos, es posible que sus errores sean, en algunos casos, complementarios. Es decir, que se equivoquen de diferentes formas, lo que podría resultar en que si se promedian sus probabilidades el resultado sea mejor. Veamos si eso sucede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8423788771993654\n"
     ]
    }
   ],
   "source": [
    "preds_avg = preds_lstm + preds\n",
    "val_pred_avg = preds_avg.argmax(axis=-1)\n",
    "print(balanced_accuracy_score(y_val, val_pred_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El hecho de promediar ambos modelos hizo que haya una mejora en los resultados, como suponiamos. Se consigue una mejora de 1% sobre el modelo con LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones\n",
    "En estre trabajo se plantean dos posibles modelos de redes neuronales para la claisificacion de texto. En ambos casos se utilizo CSA para generar los embeddings que representan a las palabras, y luego se optó por representar los documentos como colecciones de esos embeddings. Ambos modelos tuvieron buenas performances siendo el de LSTM el que dió mejores resultados. También se pudo ver que con solo promediar las probabilidades que se obtiene de cada modelo se consigue una mejora en los resultados. Cabe destacar que el preprocesamiento de datos no incluye stemming ni lemmatizacion, solamente se realizó una limpieza de algunos caracteres y stopwords, lo que muestra el poder que tiene el uso CSA para la clasificación de textos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posibles mejoras\n",
    "- En esta entrega no se utilizó ninguna forma de lemmatization o de stemming. Inicialmente no se utilizó porque varios nombres de productos resultan de palabras que no existen en el idioma o son derivados de palabras del idioma inglés, por lo que primero habría que analizar como resuelven ésto los diferentes algoritmos. Queda pendiente para probar mas adelante.\n",
    "- Utilizar la representacion que propone CSA para documentos y utilizar otro tipo de modelos para clasificar (como podrían ser SVM o RandomForest, o bien seguir con redes neuronales, pero usando solo capas densas)\n",
    "- Trabajar con ngramas de diferentes tamaños, dado que suele pasar que sean nombres compuestos. En éste trabajo se trabajó unicamente con una palabra, mas que nada por limites de la memoria RAM para el vocabulario y el calculo de CSA. Se podría haber limitado el tamaño del vocabulario, pero al haber algunas categorías con muy pocos ejemplos me preocupaba que esas categorias no tuvieran palabras que llegaran a entrar en el vocabulario lo que haria imposible clasificarlas. Queda para mas adelante hacer un analisis de esos casos y determinar un tamaño ideal para ngramas y vocabulario, o bien buscar formas de calcular CSA que requieran menos memoria.\n",
    "- Hacer un analisis mas exhaustivo de las stopwords que se definen para éste caso en particular.\n",
    "- Probar otras formas de balanceo de clases que permitan trabajar con una parte mas grande del dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comentario final\n",
    "En su momento probé de enviar en la compentencia un modelo similar al creado en éste trabajo con CNN. El modelo en sí era casi igual, pero tenia un peor preprocesamiento (sobre todo al momento de obtener ejemplos para balancear las clases de train y en la obtencion de stopwords). Dicho obtuvo la posición 35 (sobre mas de 200 participantes), con un resultado de 0.88 conta el 0.91 que obtuvo el ganador. Probablemente con las mejoras hechas en éste trabajo o las planteadas en el punto anterior el resultado hubiera estado más cerca del ganador."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
